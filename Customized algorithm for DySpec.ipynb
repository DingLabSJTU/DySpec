{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read me\n",
    "Dynamic Spectra (DySpec) is a spectrum-transforming fluorescent barcode coupled with time-lapse imaging to exponentially increase the number of co-imaged proteins. Theoretically, if *F* fluorophores are imaged in each cycle, *N* cycles of image can visualize *F<sup>N</sup>* proteins. To decode proteins from DySpec images, we developed two customized algorithms here: `Image subtraction` and `Linear unmixing`. The step-by-step operations and critical considerations are outlined in detail below.\n",
    "\n",
    "### Hardware\n",
    "- Computer workstation equipped with an AMD Ryzen 5975WX CPU\n",
    "- NVIDIA RTX 3090 graphics processing card\n",
    "\n",
    "### Software\n",
    "- [Python](https://www.python.org/).\n",
    "- [Jupyter Notebook](https://jupyter.org/).\n",
    "- [Fiji](https://imagej.net/software/fiji/downloads)\n",
    "- [ZEN](https://www.zeiss.com/microscopy/zh/products/software/zeiss-zen.html)\n",
    "- [elastix](https://elastix.dev/).\n",
    "\n",
    "### Steps to install python environment and libraries:\n",
    "\n",
    "#### 1. Install Jupyter Notebook 7.x (or Python 3.x)\n",
    "- `Jupyter Notebook 7.x` is available for download from the [official Jupyter website](https://jupyter.org/).\n",
    "- `Python 3.x` is available for download from the [official Python website](https://www.python.org/).\n",
    "\n",
    "#### 2. Update `pip` (optional)\n",
    "It's a good practice to keep `pip` up to date. Open a terminal (or command prompt) and run the following command:\n",
    "\n",
    "```bash\n",
    "python -m pip install --upgrade pip\n",
    "```\n",
    "\n",
    "#### 3. Install Required Libraries\n",
    "The required python libraries include: \n",
    "- `SimpleITK`\n",
    "- `os`\n",
    "- `cv2`\n",
    "- `numpy`\n",
    "- `shutil`\n",
    "- `pandas`\n",
    "- `PIL`\n",
    "- `openpyxl`\n",
    "- `itertools`\n",
    "- `sklearn.metrics`\n",
    "- `scipy.optimize`<br>\n",
    "\n",
    "For example, to install `numpy`, execute the following command in your terminal or command prompt:\n",
    "\n",
    "```bash\n",
    "pip install numpy\n",
    "```\n",
    "\n",
    "#### 4. Verify Installation\n",
    "After installation, you can verify that the libraries are installed correctly by running this Python script:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"cv2 version: {cv2.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "```\n",
    "\n",
    "This script will print the installed versions of the libraries. If you see the version numbers printed without any errors, the libraries were installed successfully.\n",
    "\n",
    "### Run the code\n",
    "- Execute the integrated Notebook from Step 1 to Step 7 in order.\n",
    "- Test images are included in each subfolder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Input images\n",
    "Image obtained at time point 1 (0 min):<br>\n",
    "- `T1_FAM`: FAM channel obtained at time point 1;\n",
    "- `T1_Cy3`: Cy3 channel obtained at time point 1;\n",
    "- `T1_Cy5`: Cy5 channel obtained at time point 1;\n",
    "- `T1_align`: DAPI or merged FAM/Cy3/Cy5 channel obtained at time point 1;<br>\n",
    "\n",
    "Image obtained at time point 2 (30 min):<br>\n",
    "- `T2_FAM`: FAM channel obtained at time point 2;\n",
    "- `T2_Cy3`: Cy3 channel obtained at time point 2;\n",
    "- `T2_Cy5`: Cy5 channel obtained at time point 2;\n",
    "- `T2_align`: DAPI or merged FAM/Cy3/Cy5 channel obtained at time point 2;<br>\n",
    "\n",
    "Image obtained at time point 3 (60 min):<br>\n",
    "- `T3_FAM`: FAM channel obtained at time point 3;\n",
    "- `T3_Cy3`: Cy3 channel obtained at time point 3;\n",
    "- `T3_Cy5`: Cy5 channel obtained at time point 3;\n",
    "- `T3_align`: DAPI or merged FAM/Cy3/Cy5 channel obtained at time point 3;<br>\n",
    "\n",
    "Note:\n",
    "- Both DAPI channel (stained with cell nucleus) or merged FAM/Cy3/Cy5 channel can be utilized for image registration. It’s important to note that the optimal focal planes for DAPI, FAM, Cy3, and Cy5 may differ. Any subtle variations in the DAPI channel may inadvertently impact the image registration process for FAM, Cy3, and Cy5. In contrast, the merged channel of FAM, Cy3, and Cy5 channels provides a more accurate representation of the actual results from the FAM, Cy3, and Cy5 channels.\n",
    "- To merge FAM, Cy3 and Cy5 channels, the raw image should be used in 8-bit or 16-bit grayscale mode. This standardization step is essential because different colors, when transformed to grayscale, can produce varying levels of brightness and contrast, potentially leading to misinterpretation of the relative intensities across channels.\n",
    "- All images are captured from the same regions under identical microscopic parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Image registration\n",
    "This section aims to align fluorescence images obatined at different time points, which contains two main steps:\n",
    "- `Step 1`: rigidly register the DAPI or merged FAM/Cy3/Cy5 images obtained at time point 2 and time point 3 with the one obtained at time point 1, and record the transformation parameters during the registration process.\n",
    "- `Step 2`: apply the transformation parameters to other channels (FAM, Cy3, Cy5).<br>\n",
    "\n",
    "To run tihs section:\n",
    "- This Python code uses the `SimpleITK` library to call the `elastix` and `transformix` tools for rigid registration. Before running the code, please ensure that `elastix` and `transformix` are correctly installed, and the directories containing their executable files are added to the system’s environment variables so that the code can call them properly. In addition, you need to install the following modules in the notebook environment using the following commands:\n",
    "```bash\n",
    "pip install SimpleITK\n",
    "pip install SimpleITK-SimpleElastix\n",
    "```\n",
    "Input image type: This code supports `8-bit TIFF` or `16-bit TIFF`.<br>\n",
    "Output image type: The output format is consistent with the input format.<br>\n",
    "\n",
    "- One can also use external software (provided in the '2_image_registration' folder) to achieve the same goal as this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration and transformation completed.\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def rigid_registration(fixed_image, moving_image):\n",
    "    \"\"\"\n",
    "    Perform rigid registration between fixed and moving images.\n",
    "    :param fixed_image: Fixed image for registration.\n",
    "    :param moving_image: Moving image to be registered to the fixed image.\n",
    "    :return: Transformed moving image and the transformation parameter map.\n",
    "    \"\"\"\n",
    "    elastix_image_filter = sitk.ElastixImageFilter()\n",
    "    elastix_image_filter.SetFixedImage(fixed_image)\n",
    "    elastix_image_filter.SetMovingImage(moving_image)\n",
    "\n",
    "    # Get the default rigid registration parameter map\n",
    "    parameter_map = sitk.GetDefaultParameterMap(\"rigid\")\n",
    "    elastix_image_filter.SetParameterMap(parameter_map)\n",
    "\n",
    "    # Execute the registration\n",
    "    elastix_image_filter.Execute()\n",
    "\n",
    "    # Get the result image and the transformation parameter map\n",
    "    result_image = elastix_image_filter.GetResultImage()\n",
    "    transform_map = elastix_image_filter.GetTransformParameterMap()\n",
    "\n",
    "    return result_image, transform_map\n",
    "\n",
    "\n",
    "def apply_transform(moving_image, transform_map):\n",
    "    \"\"\"\n",
    "    Apply the transformation to the moving image using the given parameter map.\n",
    "    :param moving_image: Moving image to be transformed.\n",
    "    :param transform_map: Transformation parameter map.\n",
    "    :return: Transformed moving image.\n",
    "    \"\"\"\n",
    "    transformix_image_filter = sitk.TransformixImageFilter()\n",
    "    transformix_image_filter.SetMovingImage(moving_image)\n",
    "    transformix_image_filter.SetTransformParameterMap(transform_map)\n",
    "    transformix_image_filter.Execute()\n",
    "    return transformix_image_filter.GetResultImage()\n",
    "\n",
    "\n",
    "def get_image_type(image_path):\n",
    "    \"\"\"\n",
    "    Get the pixel type of the image\n",
    "    :param image_path: Path to the image\n",
    "    :return: Pixel type string\n",
    "    \"\"\"\n",
    "    image = sitk.ReadImage(image_path)\n",
    "    pixel_id = image.GetPixelID()\n",
    "    \n",
    "    if pixel_id == sitk.sitkUInt8:\n",
    "        return sitk.sitkUInt8\n",
    "    elif pixel_id == sitk.sitkUInt16:\n",
    "        return sitk.sitkUInt16\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported pixel type for image: {image_path}\")\n",
    "\n",
    "\n",
    "# Input image names\n",
    "image_names = [\n",
    "    \"T1_FAM\", \"T1_Cy3\", \"T1_Cy5\", \"T1_merge\",\n",
    "    \"T2_FAM\", \"T2_Cy3\", \"T2_Cy5\", \"T2_merge\",\n",
    "    \"T3_FAM\", \"T3_Cy3\", \"T3_Cy5\", \"T3_merge\"\n",
    "]\n",
    "\n",
    "# Directory where the input images are stored\n",
    "input_dir = \"D://Customized algorithm for DySpec//1_input_image\"\n",
    "# Directory where the output images will be saved\n",
    "output_dir = \"D://Customized algorithm for DySpec//2_image_registration\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Read the fixed image (T1_merge)\n",
    "fixed_image_name = \"T1_merge\"\n",
    "fixed_image_path = os.path.join(input_dir, f\"{fixed_image_name}.tif\")\n",
    "fixed_image_type = get_image_type(fixed_image_path)\n",
    "fixed_image = sitk.ReadImage(fixed_image_path, fixed_image_type)\n",
    "\n",
    "# Dictionary to store transformation parameter maps\n",
    "transformation_maps = {}\n",
    "\n",
    "# First align T2_merge and T3_merge to T1_merge\n",
    "for time_point in [2, 3]:\n",
    "    merge_image_name = f\"T{time_point}_merge\"\n",
    "    merge_image_path = os.path.join(input_dir, f\"{merge_image_name}.tif\")\n",
    "    \n",
    "    # Read image with original type\n",
    "    image_type = get_image_type(merge_image_path)\n",
    "    merge_image = sitk.ReadImage(merge_image_path, image_type)\n",
    "    \n",
    "    # Perform rigid registration\n",
    "    aligned_merge_image, transform_map = rigid_registration(fixed_image, merge_image)\n",
    "    \n",
    "    # Convert back to original type\n",
    "    aligned_merge_image = sitk.Cast(aligned_merge_image, image_type)\n",
    "    \n",
    "    # Save the aligned merge image\n",
    "    aligned_output_path = os.path.join(output_dir, f\"aligned_{merge_image_name}.tif\")\n",
    "    sitk.WriteImage(aligned_merge_image, aligned_output_path)\n",
    "    \n",
    "    # Store the transformation map for later use\n",
    "    transformation_maps[time_point] = transform_map\n",
    "\n",
    "# Apply transformations to FAM, Cy3, Cy5 channels using corresponding merge image transforms\n",
    "for time_point in [2, 3]:\n",
    "    # Get the transformation map from the corresponding merge image\n",
    "    transform_map = transformation_maps[time_point]\n",
    "    \n",
    "    # Apply the transformation to FAM, Cy3, Cy5 channels\n",
    "    for channel in [\"FAM\", \"Cy3\", \"Cy5\"]:\n",
    "        channel_image_name = f\"T{time_point}_{channel}\"\n",
    "        channel_image_path = os.path.join(input_dir, f\"{channel_image_name}.tif\")\n",
    "        \n",
    "        # Read image with original type\n",
    "        image_type = get_image_type(channel_image_path)\n",
    "        channel_image = sitk.ReadImage(channel_image_path, image_type)\n",
    "        \n",
    "        # Apply the transformation\n",
    "        aligned_channel_image = apply_transform(channel_image, transform_map)\n",
    "        \n",
    "        # Convert back to original type\n",
    "        aligned_channel_image = sitk.Cast(aligned_channel_image, image_type)\n",
    "        \n",
    "        # Save the aligned channel image\n",
    "        aligned_output_path = os.path.join(output_dir, f\"aligned_{channel_image_name}.tif\")\n",
    "        sitk.WriteImage(aligned_channel_image, aligned_output_path)\n",
    "\n",
    "print(\"Registration and transformation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is recommended to input images that exhibit visible consistency to the unaided eye. Significant discrepancies between matched images may lead to alignment failure. Below, you'll find supplementary code to assess whether portions of the images can be successfully processed. If you encounter a warning stating \"Failed to align XXX. Exiting.\", please revise your input images accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded image from D://Customized algorithm for DySpec//1_input_image//0_DAPI0.tif with shape (1024, 1024, 3)\n",
      "Successfully loaded image from D://Customized algorithm for DySpec//1_input_image//0_DAPI.tif with shape (1024, 1024, 3)\n",
      "Successfully loaded image from D://Customized algorithm for DySpec//1_input_image//0_CY5.tif with shape (1024, 1024, 3)\n",
      "Successfully loaded image from D://Customized algorithm for DySpec//1_input_image//0_CY3.tif with shape (1024, 1024, 3)\n",
      "Successfully loaded image from D://Customized algorithm for DySpec//1_input_image//0_FAM.tif with shape (1024, 1024, 3)\n",
      "Aligned channels for DAPI successfully.\n",
      "Aligned DAPI saved as 'aligned_DAPI.tif'.\n",
      "Aligned CY5 saved as 'aligned_CY5.tif'.\n",
      "Aligned CY3 saved as 'aligned_CY3.tif'.\n",
      "Aligned FAM saved as 'aligned_FAM.tif'.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image at {image_path}. Check the file path and integrity.\")\n",
    "    else:\n",
    "        # Optionally resize the image to reduce memory usage\n",
    "        print(f\"Successfully loaded image from {image_path} with shape {image.shape}\")\n",
    "    return image\n",
    "\n",
    "def align_images(base_image, target_image):\n",
    "    if base_image is None or target_image is None:\n",
    "        print(\"Error: One of the images is not loaded.\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        # Convert images to grayscale\n",
    "        base_gray = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
    "        target_gray = cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Initialize SIFT detector\n",
    "        sift = cv2.SIFT_create()\n",
    "\n",
    "        # Find the keypoints and descriptors with SIFT\n",
    "        kp1, des1 = sift.detectAndCompute(base_gray, None)\n",
    "        kp2, des2 = sift.detectAndCompute(target_gray, None)\n",
    "\n",
    "        # Check if descriptors are found\n",
    "        if des1 is None or des2 is None:\n",
    "            print(\"Error: Descriptors not found in one of the images.\")\n",
    "            return None, None\n",
    "\n",
    "        # FLANN parameters\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "\n",
    "        # Initialize FLANN matcher\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "        # Match descriptors using KNN\n",
    "        matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "        # Store good matches as per Lowe's ratio test.\n",
    "        good_matches = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.7 * n.distance:\n",
    "                good_matches.append(m)\n",
    "\n",
    "        if len(good_matches) > 4:\n",
    "            src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "            # Calculate Homography\n",
    "            H, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "            # Warp target image to align with the base image\n",
    "            aligned_image = cv2.warpPerspective(target_image, H, (base_image.shape[1], base_image.shape[0]))\n",
    "            return aligned_image, H\n",
    "        else:\n",
    "            print(\"Error: Not enough matches found.\")\n",
    "            return None, None\n",
    "    except cv2.error as e:\n",
    "        print(f\"OpenCV error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Load images\n",
    "DAPI0 = load_image(r'D://Customized algorithm for DySpec//1_input_image//0_DAPI0.tif')\n",
    "DAPI = load_image(r'D://Customized algorithm for DySpec//1_input_image//0_DAPI.tif')\n",
    "\n",
    "# Align DAPI to DAPI0 if loaded successfully\n",
    "if DAPI0 is not None and DAPI is not None:\n",
    "    aligned_DAPI, H2 = align_images(DAPI0, DAPI)\n",
    "    if aligned_DAPI is None:\n",
    "        print(\"Failed to align DAPI. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "# Load channels for DAPI (CY5, CY3, FAM)\n",
    "CY5 = load_image(r'D://Customized algorithm for DySpec//1_input_image//0_CY5.tif')\n",
    "CY3 = load_image(r'D://Customized algorithm for DySpec//1_input_image//0_CY3.tif')\n",
    "FAM = load_image(r'D://Customized algorithm for DySpec//1_input_image//0_FAM.tif')\n",
    "\n",
    "if CY5 is not None and CY3 is not None and FAM is not None:\n",
    "    # Apply the same transformation to channels\n",
    "    aligned_CY5 = cv2.warpPerspective(CY5, H2, (DAPI0.shape[1], DAPI0.shape[0]))\n",
    "    aligned_CY3 = cv2.warpPerspective(CY3, H2, (DAPI0.shape[1], DAPI0.shape[0]))\n",
    "    aligned_FAM = cv2.warpPerspective(FAM, H2, (DAPI0.shape[1], DAPI0.shape[0]))\n",
    "    print(\"Aligned channels for DAPI successfully.\")\n",
    "else:\n",
    "    print(\"Failed to load one or more channels for DAPI. Exiting.\")\n",
    "\n",
    "# Save aligned images\n",
    "if aligned_DAPI is not None:\n",
    "    cv2.imwrite('D://Customized algorithm for DySpec//2_image_registration//0_aligned_DAPI.tif', aligned_DAPI)\n",
    "    print(\"Aligned DAPI saved as 'aligned_DAPI.tif'.\")\n",
    "\n",
    "if aligned_CY5 is not None:\n",
    "    cv2.imwrite('D://Customized algorithm for DySpec//2_image_registration//0_aligned_CY5.tif', aligned_CY5)\n",
    "    print(\"Aligned CY5 saved as 'aligned_CY5.tif'.\")\n",
    "\n",
    "if aligned_CY3 is not None:\n",
    "    cv2.imwrite('D://Customized algorithm for DySpec//2_image_registration//0_aligned_CY3.tif', aligned_CY3)\n",
    "    print(\"Aligned CY3 saved as 'aligned_CY3.tif'.\")\n",
    "\n",
    "if aligned_FAM is not None:\n",
    "    cv2.imwrite('D://Customized algorithm for DySpec//2_image_registration//0_aligned_FAM.tif', aligned_FAM)\n",
    "    print(\"Aligned FAM saved as 'aligned_FAM.tif'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Image trim\n",
    "- This step aims to trim the aligned images to a uniform size.\n",
    "- Image trim for DAPI channels is unnecessary, as DAPI is displayed in the final merged images.\n",
    "- The following Java code is executed within [Fiji](https://imagej.net/software/fiji/downloads) to accomplish this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate a customized code: Open Fiji → Plugins → Macro → Record\n",
    "# To run the code: Open Fiji → Process → Batch → Macro\n",
    "# Input folder: D:///Customized algorithm for DySpec//3_image_trim//Fiji_input\n",
    "# Output folder: D:///Customized algorithm for DySpec//3_image_trim//Fiji_output\n",
    "//setTool(\"rectangle\");\n",
    "makeRectangle(60, 32, 900, 900);\n",
    "# To choose an appropriate size to crop: Open Fiji → open one of the image → choose Rectangle → the size will be shown in the software: x=4.18 (129), y=5.11 (315), w=0.50 (1024), h=0.46 (1024);\n",
    "# The cropped dimensions will be: 1024px* 1024px, as illustrated by the values w=0.50 (1024), h=0.46 (1024);\n",
    "run(\"Crop\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Image Subtraction\n",
    "This algorithm based on the theory that when two images are merged, the fluorescence intensity of the combined image equals the sum of the intensities of the individual images (Image1+2 = Image1 + Image2). Conversely, by subtracting one image (Image1) from the merged image (Image1+2), the other image (Image2) can be resolved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decoding β-Tubulin from DySpec images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Import images\n",
    "ImageC1 = cv2.imread('D://Customized algorithm for DySpec//4_image_subtraction//T3_FAM.tif', cv2.IMREAD_GRAYSCALE)\n",
    "ImageC2 = cv2.imread('D://Customized algorithm for DySpec//4_image_subtraction//T1_Cy3.tif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get the size of each image\n",
    "height, width = ImageC1.shape\n",
    "\n",
    "# Create an empty matrix to store the new gray value\n",
    "new_gray_values = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "# Traverse each pixel coordinate\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        # Calculate the new gray value according to the pre-set color barcode (the following is just an example for SV2)\n",
    "        if ImageC1[i, j] > ImageC2[i, j]:\n",
    "            new_gray_values[i, j] = ImageC1[i, j] - ImageC2[i, j]\n",
    "        else:\n",
    "            new_gray_values[i, j] = 0\n",
    "# Convert the new grayscale value matrix to an image\n",
    "cv2.imwrite('D://Customized algorithm for DySpec//4_image_subtraction//01_Tubulin.tif', new_gray_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decoding Vimentin from DySpec images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_and_rename_tif_file(directory):\n",
    "    \n",
    "    source_path = os.path.join(directory, \"D://Customized algorithm for DySpec//4_image_subtraction//T1_Cy3.tif\")\n",
    "    target_path = os.path.join(directory, \"D://Customized algorithm for DySpec//4_image_subtraction//02_Vimentin.tif\")\n",
    "    \n",
    "    try:\n",
    "        # Check if the source file exists\n",
    "        if not os.path.exists(source_path):\n",
    "            print(f\"Error: Source file {source_path} does not exist\")\n",
    "            return False\n",
    "        \n",
    "        # Check if the target file already exists\n",
    "        if os.path.exists(target_path):\n",
    "            print(f\"Error: Target file {target_path} already exists\")\n",
    "            return False\n",
    "        \n",
    "        # Copy the file (preserves metadata)\n",
    "        shutil.copy2(source_path, target_path)\n",
    "        print(True)\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An exception occurred during copy operation: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the directory path directly in the code\n",
    "    directory_path = \"/path/to/your/tif/files\"  # Replace with your actual path\n",
    "    copy_and_rename_tif_file(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decoding PKC-α from DySpec images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_and_rename_tif_file(directory):\n",
    "    \n",
    "    source_path = os.path.join(directory, \"D://Customized algorithm for DySpec//4_image_subtraction//T2_FAM.tif\")\n",
    "    target_path = os.path.join(directory, \"D://Customized algorithm for DySpec//4_image_subtraction//03_PKC.tif\")\n",
    "    \n",
    "    try:\n",
    "        # Check if the source file exists\n",
    "        if not os.path.exists(source_path):\n",
    "            print(f\"Error: Source file {source_path} does not exist\")\n",
    "            return False\n",
    "        \n",
    "        # Check if the target file already exists\n",
    "        if os.path.exists(target_path):\n",
    "            print(f\"Error: Target file {target_path} already exists\")\n",
    "            return False\n",
    "        \n",
    "        # Copy the file (preserves metadata)\n",
    "        shutil.copy2(source_path, target_path)\n",
    "        print(True)\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An exception occurred during copy operation: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the directory path directly in the code\n",
    "    directory_path = \"/path/to/your/tif/files\"  # Replace with your actual path\n",
    "    copy_and_rename_tif_file(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decoding Chx10 from DySpec images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_and_rename_tif_file(directory):\n",
    "  \n",
    "    source_path = os.path.join(directory, \"D://Customized algorithm for DySpec//4_image_subtraction//T3_Cy5.tif\")\n",
    "    target_path = os.path.join(directory, \"D://Customized algorithm for DySpec//4_image_subtraction//04_Chx10.tif\")\n",
    "    \n",
    "    try:\n",
    "        # Check if the source file exists\n",
    "        if not os.path.exists(source_path):\n",
    "            print(f\"Error: Source file {source_path} does not exist\")\n",
    "            return False\n",
    "        \n",
    "        # Check if the target file already exists\n",
    "        if os.path.exists(target_path):\n",
    "            print(f\"Error: Target file {target_path} already exists\")\n",
    "            return False\n",
    "        \n",
    "        # Copy the file (preserves metadata)\n",
    "        shutil.copy2(source_path, target_path)\n",
    "        print(True)\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: An exception occurred during copy operation: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the directory path directly in the code\n",
    "    directory_path = \"/path/to/your/tif/files\"  # Replace with your actual path\n",
    "    copy_and_rename_tif_file(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decoding SV2 from DySpec images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Import images\n",
    "ImageC1 = cv2.imread('D://Customized algorithm for DySpec//4_image_subtraction//T1_FAM.tif', cv2.IMREAD_GRAYSCALE)\n",
    "ImageC2 = cv2.imread('D://Customized algorithm for DySpec//4_image_subtraction//T2_FAM.tif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get the size of each image\n",
    "height, width = ImageC1.shape\n",
    "\n",
    "# Create an empty matrix to store the new gray value\n",
    "new_gray_values = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "# Traverse each pixel coordinate\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        if ImageC1[i, j] > ImageC2[i, j]:\n",
    "            new_gray_values[i, j] = ImageC1[i, j] - ImageC2[i, j]\n",
    "        else:\n",
    "            new_gray_values[i, j] = 0\n",
    "# Convert the new grayscale value matrix to an image\n",
    "cv2.imwrite('D://Customized algorithm for DySpec//4_image_subtraction//05_SV2.tif', new_gray_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decoding Synapsin from DySpec images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Import images\n",
    "ImageC1 = cv2.imread('D://Customized algorithm for DySpec//4_image_subtraction//T2_Cy3.tif', cv2.IMREAD_GRAYSCALE)\n",
    "ImageC2 = cv2.imread('D://Customized algorithm for DySpec//4_image_subtraction//T1_Cy3.tif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Get the size of each image\n",
    "height, width = ImageC1.shape\n",
    "\n",
    "# Create an empty matrix to store the new gray value\n",
    "new_gray_values = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "# Traverse each pixel coordinate\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        # Calculate the new gray value according to the pre-set color barcode (the following is just an example for SV2)\n",
    "        if ImageC1[i, j] > ImageC2[i, j]:\n",
    "            new_gray_values[i, j] = ImageC1[i, j] - ImageC2[i, j]\n",
    "        else:\n",
    "            new_gray_values[i, j] = 0\n",
    "# Convert the new grayscale value matrix to an image\n",
    "cv2.imwrite('D://Customized algorithm for DySpec//4_image_subtraction//06_Synapsin.tif', new_gray_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Linear unmixing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each pixel in the DySpec image, the color-changing information over different time points is stored in a one-dimensional array_m and displayed as follows: \n",
    "```\n",
    "array_m = np.array([T1_FAM, T1_Cy3, T1_Cy5, T2_FAM, T2_Cy3, T2_Cy5, T3_FAM, T3_Cy3, T3_Cy5])\n",
    "```\n",
    "\n",
    "- `T1_FAM`: FAM channel obtained at time point 1 (0 min in this study)\n",
    "- `T1_Cy3`: Cy3 channel obtained at time point 1 (0 min in this study)\n",
    "- `T1_Cy5`: Cy5 channel obtained at time point 1 (0 min in this study)\n",
    "- `T2_FAM`: FAM channel obtained at time point 2 (30 min in this study)\n",
    "- `T2_Cy3`: Cy3 channel obtained at time point 2 (30 min in this study)\n",
    "- `T2_Cy5`: Cy5 channel obtained at time point 2 (30 min in this study)\n",
    "- `T3_FAM`: FAM channel obtained at time point 3 (60 min in this study)\n",
    "- `T3_Cy3`: Cy3 channel obtained at time point 3 (60 min in this study)\n",
    "- `T3_Cy5`: Cy5 channel obtained at time point 3 (60 min in this study)\n",
    "\n",
    "The color-changing information for each pixel is stored in a worksheet, where the cell coordinates correspond to the pixel coordinates in the image.<br>\n",
    "\n",
    "The fundamental concept of linear unmixing is based on the following formula:\n",
    "\n",
    " `array_m = C1*array_1 + C2*array_2 + …… + Cn*array_n`\n",
    "\n",
    "- `array_m`：Color-changing information of each pixel.\n",
    "- `array_1` ~ `array_n`: Spectrum-transforming fluorescent barcode of each protein.\n",
    "- `contribution factor (C)`: Contribution of array_n in making up array_m, which also corresponds to the relative intensity of the recontrasted image.\n",
    "- The mismatch score, represented by the Mean Squared Error (MSE), can be fine-tuned to achieve optimal results. In our study, a threshold of MSE < 20 is applied, and values exceeding this threshold are deemed unreliable and excluded from analysis (i.e., set to zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Extra color-changing information from raw images to one-dimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grayscale values have been exported to D://Customized algorithm for DySpec//5_linear_unmixing//raw_color_changing_information.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# image file path\n",
    "image_files = [\n",
    "    'D://Customized algorithm for DySpec//5_linear_unmixing//T1_FAM.tif',\n",
    "    'D://Customized algorithm for DySpec//5_linear_unmixing//T1_Cy3.tif',\n",
    "    'D://Customized algorithm for DySpec//5_linear_unmixing//T1_Cy5.tif',\n",
    "    'D://Customized algorithm for DySpec//5_linear_unmixing//T2_FAM.tif',\n",
    "    'D://Customized algorithm for DySpec//5_linear_unmixing//T2_Cy3.tif',\n",
    "    'D://Customized algorithm for DySpec//5_linear_unmixing//T2_Cy5.tif',\n",
    "    'D://Customized algorithm for DySpec//5_linear_unmixing//T3_FAM.tif',\n",
    "    'D://Customized algorithm for DySpec//5_linear_unmixing//T3_Cy3.tif',\n",
    "    'D://Customized algorithm for DySpec//5_linear_unmixing//T3_Cy5.tif'\n",
    "]\n",
    "\n",
    "# create a new workbook\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Gray Values\"\n",
    "\n",
    "# create a dictionary to store the grayscale values of coordinates\n",
    "gray_value_dict = {}\n",
    "\n",
    "# iterate through each image file\n",
    "for image_file in image_files:\n",
    "    with Image.open(image_file) as img:\n",
    "        \n",
    "        # get image size\n",
    "        width, height = img.size\n",
    "        \n",
    "        # extract the grayscale value of each pixel\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                value = img.getpixel((x, y))\n",
    "                \n",
    "                # use the coordinates (x, y) as the key in the dictionary\n",
    "                if (x, y) not in gray_value_dict:\n",
    "                    gray_value_dict[(x, y)] = []\n",
    "                gray_value_dict[(x, y)].append(value)\n",
    "\n",
    "# write the grayscale values to the worksheet\n",
    "for (x, y), values in gray_value_dict.items():\n",
    "    # Combine grayscale values with the same coordinates into a one-dimensional array\n",
    "    combined_values = ', '.join(map(str, values))\n",
    "    ws.cell(row=y + 1, column=x + 1, value=combined_values)\n",
    "\n",
    "# write the grayscale values to the worksheet\n",
    "output_file = 'D://Customized algorithm for DySpec//5_linear_unmixing//raw_color_changing_information.xlsx'\n",
    "wb.save(output_file)\n",
    "\n",
    "print(f\"grayscale values have been exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Linear unmixing of six retinal proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to contribution_factor.xlsx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import nnls\n",
    "import openpyxl\n",
    "\n",
    "# Read the color-changing information of each pixel\n",
    "input_df = pd.read_excel('D://Customized algorithm for DySpec//5_linear_unmixing//raw_color_changing_information.xlsx', header=None)\n",
    "\n",
    "# Spectrum-transforming fluorescent barcodes assigned to each protein\n",
    "arrays = [\n",
    "  np.array([0, 0, 1, 0, 0, 1, 1, 0, 0]), #1_β-Tubulin\n",
    "  np.array([0, 1, 0, 0, 1, 0, 1, 0, 0]), #2_Vimentin\n",
    "  np.array([1, 0, 0, 1, 0, 0, 0, 1, 0]), #3_PKC-α\n",
    "  np.array([0, 0, 1, 0, 0, 1, 0, 0, 1]), #4_Chx10\n",
    "  np.array([1, 0, 0, 0, 0, 1, 0, 1, 0]), #5_SV2\n",
    "  np.array([0, 0, 1, 0, 1, 0, 0, 1, 0]), #6_Synapsin\n",
    "]\n",
    "\n",
    "def find_combinations(array_m, arrays, max_arrays=6):\n",
    "    best_combination = None\n",
    "    best_constants = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for n in range(1, max_arrays + 1):\n",
    "        for combo in combinations(enumerate(arrays), n):\n",
    "            indices, selected_arrays = zip(*combo)\n",
    "            \n",
    "            A = np.array(selected_arrays).T\n",
    "            b = array_m\n",
    "            try:\n",
    "                constants, _ = nnls(A, b)\n",
    "                predicted = np.dot(A, constants)\n",
    "                score = mean_squared_error(array_m, predicted)\n",
    "                \n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_combination = indices\n",
    "                    best_constants = constants\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    return best_combination, best_constants, best_score\n",
    "\n",
    "# Creat a new Excel file to store results\n",
    "workbook = openpyxl.Workbook()\n",
    "\n",
    "# Define the sheet with array and protein name\n",
    "sheet_names = ['1_Tubulin', '2_Vimentin', '3_PKC', '4_Chx10', '5_SV2', '6_Synapsin', 'Mismatch Score']\n",
    "\n",
    "# Create an empty DataFrame for each sheet and fill it with 0.0\n",
    "results = {name: pd.DataFrame(0.0, index=input_df.index, columns=input_df.columns, dtype=float) for name in sheet_names}\n",
    "\n",
    "# Calculate the optimal combination for each cell\n",
    "for row in range(input_df.shape[0]):\n",
    "    for col in range(input_df.shape[1]):\n",
    "        cell_value = input_df.iloc[row, col]\n",
    "        if pd.notna(cell_value):  # Check if the cell is empty\n",
    "            array_m = np.array([float(x) for x in str(cell_value).split(',')])  # Convert the cell value to an array\n",
    "            if len(array_m) == len(arrays[0]):  # Ensure length matches\n",
    "                combination, constants, score = find_combinations(array_m, arrays)\n",
    "                \n",
    "                if score <= 20:\n",
    "                    for i, const in zip(combination, constants):\n",
    "                        results[sheet_names[i]].iloc[row, col] = const\n",
    "                \n",
    "                results['Mismatch Score'].iloc[row, col] = score\n",
    "            else:\n",
    "                print(f\"Warning: Mismatch in array length at row {row+1}, column {col+1}\")\n",
    "\n",
    "# Write the results to Excel file\n",
    "with pd.ExcelWriter('D://Customized algorithm for DySpec//5_linear_unmixing//contribution_factor.xlsx', engine='openpyxl') as writer:\n",
    "    for sheet_name, df in results.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)\n",
    "\n",
    "print(\"Results have been written to contribution_factor.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Linear unmixing of 20 breast cancer proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been written to contribution_factor.xlsx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import nnls\n",
    "import openpyxl\n",
    "\n",
    "# Read the color-changing information of each pixel\n",
    "input_df = pd.read_excel('D://Customized algorithm for DySpec//5_linear_unmixing//raw_color_changing_information.xlsx', header=None)\n",
    "\n",
    "# Spectrum-transforming fluorescent barcodes assigned to each protein\n",
    "arrays = [\n",
    "  np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]), #1_CD3\n",
    "  np.array([1, 0, 0, 0, 0, 1, 0, 1, 0]), #2_CD4\n",
    "  np.array([0, 1, 0, 0, 0, 1, 1, 0, 0]), #3_CD8a\n",
    "  np.array([0, 1, 0, 1, 0, 0, 0, 0, 1]), #4_CD19\n",
    "  np.array([0, 0, 1, 0, 1, 0, 1, 0, 0]), #5_CD20\n",
    "  np.array([0, 0, 1, 1, 0, 0, 0, 1, 0]), #6_CD45RA\n",
    "  np.array([1, 0, 0, 0, 1, 0, 1, 0, 0]), #7_CD45RO\n",
    "  np.array([1, 0, 0, 0, 0, 1, 1, 0, 0]), #8_CD56\n",
    "  np.array([0, 1, 0, 1, 0, 0, 0, 1, 0]), #9_CD68\n",
    "  np.array([0, 1, 0, 0, 0, 1, 0, 1, 0]), #10_CD80\n",
    "  np.array([0, 0, 1, 1, 0, 0, 0, 0, 1]), #11_CD163\n",
    "  np.array([0, 0, 1, 0, 1, 0, 0, 0, 1]), #12_Foxp3\n",
    "  np.array([0, 1, 0, 1, 0, 0, 1, 0, 0]), #13_GZMB\n",
    "  np.array([1, 0, 0, 0, 0, 1, 0, 0, 1]), #14_MPO\n",
    "  np.array([1, 0, 0, 0, 1, 0, 0, 1, 0]), #15_HER2\n",
    "  np.array([0, 1, 0, 0, 0, 1, 0, 0, 1]), #16_CK19\n",
    "  np.array([0, 0, 1, 1, 0, 0, 1, 0, 0]), #17_PIP\n",
    "  np.array([0, 0, 1, 0, 1, 0, 0, 1, 0]), #18_α-SMA\n",
    "  np.array([1, 0, 0, 1, 0, 0, 0, 1, 0]), #19_CD31\n",
    "  np.array([1, 0, 0, 1, 0, 0, 0, 0, 1]), #20_Ki-67\n",
    "]\n",
    "\n",
    "def find_combinations(array_m, arrays, max_arrays=3):\n",
    "    best_combination = None\n",
    "    best_constants = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for n in range(1, max_arrays + 1):\n",
    "        for combo in combinations(enumerate(arrays), n):\n",
    "            indices, selected_arrays = zip(*combo)\n",
    "            \n",
    "            A = np.array(selected_arrays).T\n",
    "            b = array_m\n",
    "            try:\n",
    "                constants, _ = nnls(A, b)\n",
    "                predicted = np.dot(A, constants)\n",
    "                score = mean_squared_error(array_m, predicted)\n",
    "                \n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_combination = indices\n",
    "                    best_constants = constants\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    return best_combination, best_constants, best_score\n",
    "\n",
    "# Creat a new Excel file to store results\n",
    "workbook = openpyxl.Workbook()\n",
    "\n",
    "# Define the sheet with array and protein name\n",
    "sheet_names = ['1_CD3', '2_CD4', '3_CD8a', '4_CD19', '5_CD20', '6_CD45RA', '7_CD45RO', '8_CD56', '9_CD68', '10_CD80',\n",
    "               '11_CD163', '12_Foxp3', '13_GZMB', '14_MPO', '15_HER2', '16_CK19', '17_PIP', '18_SMA', '19_CD31', '20_Ki67',\n",
    "               'Mismatch Score']\n",
    "\n",
    "# Create an empty DataFrame for each sheet and fill it with 0.0\n",
    "results = {name: pd.DataFrame(0.0, index=input_df.index, columns=input_df.columns, dtype=float) for name in sheet_names}\n",
    "\n",
    "# Calculate the optimal combination for each cell\n",
    "for row in range(input_df.shape[0]):\n",
    "    for col in range(input_df.shape[1]):\n",
    "        cell_value = input_df.iloc[row, col]\n",
    "        if pd.notna(cell_value):  # Check if the cell is empty\n",
    "            array_m = np.array([float(x) for x in str(cell_value).split(',')])  # Convert the cell value to an array\n",
    "            if len(array_m) == len(arrays[0]):  # Ensure length matches\n",
    "                combination, constants, score = find_combinations(array_m, arrays)\n",
    "                \n",
    "                if score <= 20:\n",
    "                    for i, const in zip(combination, constants):\n",
    "                        results[sheet_names[i]].iloc[row, col] = const\n",
    "                \n",
    "                results['Mismatch Score'].iloc[row, col] = score\n",
    "            else:\n",
    "                print(f\"Warning: Mismatch in array length at row {row+1}, column {col+1}\")\n",
    "\n",
    "# Write the results to Excel file\n",
    "with pd.ExcelWriter('D://Customized algorithm for DySpec//5_linear_unmixing//contribution_factor.xlsx', engine='openpyxl') as writer:\n",
    "    for sheet_name, df in results.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)\n",
    "\n",
    "print(\"Results have been written to contribution_factor.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Image display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To `show image`: The raw data containing the contribution factor was displayed as a grayscale image (.tif) using the following code.\n",
    "- To assign the decoded image (grayscale) with `pseudo color`: Open zen 3.11 software → Dimensions → Channels → Change clor.\n",
    "- To `merge images` of different proteins: Open zen 3.11 software → Processing → Method → Add channes.\n",
    "- zen 3.11 software can be downloaded from the [official Zeiss software website](https://www.zeiss.com/microscopy/zh/products/software/zeiss-zen.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/1_CD3.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/2_CD4.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/3_CD8a.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/4_CD19.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/5_CD20.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/6_CD45RA.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/7_CD45RO.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/8_CD56.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/9_CD68.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/10_CD80.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/11_CD163.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/12_Foxp3.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/13_GZMB.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/14_MPO.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/15_HER2.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/16_CK19.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/17_PIP.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/18_SMA.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/19_CD31.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/20_Ki67.tif\n",
      "TIFF image has been saved to D://Customized algorithm for DySpec//6_image_display/Match Score.tif\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def excel_to_tiff(excel_path, output_dir):\n",
    "    # Open the Excel file\n",
    "    workbook = openpyxl.load_workbook(excel_path)\n",
    "\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        sheet = workbook[sheet_name]\n",
    "\n",
    "        # Get the dimensions of the Excel sheet\n",
    "        max_row = sheet.max_row\n",
    "        max_col = sheet.max_column\n",
    "\n",
    "        # Create a numpy array to store grayscale values, with data type np.uint8 (8-bit)\n",
    "        image_array = np.zeros((max_row, max_col), dtype=np.uint8)\n",
    "\n",
    "        # Read values from the Excel sheet and populate the array\n",
    "        for row in range(1, max_row + 1):\n",
    "            for col in range(1, max_col + 1):\n",
    "                cell_value = sheet.cell(row=row, column=col).value\n",
    "                if cell_value is not None:\n",
    "                    # Ensure the value is within the range of an 8-bit unsigned integer (0-255)\n",
    "                    cell_value = max(0, min(int(cell_value), 255))\n",
    "                    image_array[row - 1, col - 1] = cell_value\n",
    "\n",
    "        # Create an image with 8-bit mode ('L' for grayscale)\n",
    "        image = Image.fromarray(image_array, mode='L')\n",
    "\n",
    "        # Construct the output file path, naming it after the sheet name\n",
    "        tiff_path = f\"{output_dir}/{sheet_name}.tif\"\n",
    "\n",
    "        # Save the image as a TIFF file\n",
    "        image.save(tiff_path, format='TIFF')\n",
    "        print(f\"TIFF image has been saved to {tiff_path}\")\n",
    "\n",
    "# Specify the input Excel file path and output directory path\n",
    "excel_file_path = r\"D://Customized algorithm for DySpec//6_image_display//contribution_factor.xlsx\"  # Replace with your Excel file path\n",
    "output_directory = r\"D://Customized algorithm for DySpec//6_image_display\"  # Replace with the directory path where you want to save the TIFF files\n",
    "\n",
    "# Call the function\n",
    "excel_to_tiff(excel_file_path, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Pixel evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The F1 score ranges from 0 to 1, with 1 indicating perfect precision and recall, and 0 indicating the worst performance. F1 score was computed by comparing the decoded images and adjacent IF images. This comparison was conducted independently for each field of view and individual protein, using the following formula:<br>\n",
    "`F1 Score=2TP/(2TP+FP+FN)`<br>\n",
    "where TP represents true positive; FP represents false positive; and FN represents false negative.\n",
    "- The calculations of the F1 score and Pearson correlation coefficient depend on the threshold value used to distinguish between negative and positive values, and are independent of whether the data is represented in 8-bit or 16-bit format.\n",
    "- The DySpec-reconstructed images are compared with adjacent IF images at the pixel level, as DySpec and standard IF cannot be conducted on the same tissue. The comparative  results may be somewhat inferior than those observed directly from the same slide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 F1 score and person correction efficient with automatic threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for paired comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9934\n",
      "Pearson correlation coefficient (R): 0.9911\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Read 8-bit (or 16-bit) grayscale images\n",
    "test_image = cv2.imread('D://Customized algorithm for DySpec//7_pixel_evaluation//reconstructed image.tif', cv2.IMREAD_GRAYSCALE)\n",
    "groundtruth_image = cv2.imread('D://Customized algorithm for DySpec//7_pixel_evaluation//adjacent IF image.tif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if images were successfully read\n",
    "if test_image is None or groundtruth_image is None:\n",
    "    print(\"Unable to read images, please check file paths and filenames.\")\n",
    "else:\n",
    "    # Binarize using Otsu's method\n",
    "    _, test_binary = cv2.threshold(test_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    _, groundtruth_binary = cv2.threshold(groundtruth_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Convert binary images to one-dimensional arrays\n",
    "    test_flat = test_binary.flatten()\n",
    "    groundtruth_flat = groundtruth_binary.flatten()\n",
    "\n",
    "    # Convert arrays to 0 and 1 format\n",
    "    test_flat = (test_flat / 255).astype(int)\n",
    "    groundtruth_flat = (groundtruth_flat / 255).astype(int)\n",
    "\n",
    "    # Calculate F1 score, setting zero_division parameter\n",
    "    f1 = f1_score(groundtruth_flat, test_flat, zero_division=0)\n",
    "\n",
    "    print(f\"F1 score: {f1:.4f}\")\n",
    "\n",
    "    # Calculate Pearson correlation coefficient\n",
    "    r = np.corrcoef(test_flat, groundtruth_flat)[0, 1]\n",
    "    print(f\"Pearson correlation coefficient (R): {r:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for batch comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 01_Tubulin and 1_Tubulin\n",
      "F1 score: 0.9481\n",
      "Pearson correlation coefficient (R): 0.9449\n",
      "\n",
      "Processing: 02_Vimentin and 2_Vimentin\n",
      "F1 score: 0.4875\n",
      "Pearson correlation coefficient (R): 0.4092\n",
      "\n",
      "Processing: 03_PKC and 3_PKC\n",
      "F1 score: 0.9584\n",
      "Pearson correlation coefficient (R): 0.9487\n",
      "\n",
      "Processing: 04_Chx10 and 4_Chx10\n",
      "F1 score: 0.9689\n",
      "Pearson correlation coefficient (R): 0.9589\n",
      "\n",
      "Processing: 05_SV2 and 5_SV2\n",
      "F1 score: 0.9401\n",
      "Pearson correlation coefficient (R): 0.9370\n",
      "\n",
      "Processing: 06_Synapsin and 6_Synapsin\n",
      "F1 score: 0.9916\n",
      "Pearson correlation coefficient (R): 0.9910\n",
      "\n",
      "All pairs processed\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "\n",
    "def calculate_metrics(test_path, gt_path):\n",
    "    \"\"\"Calculate F1 score and Pearson correlation coefficient for a single pair of images\"\"\"\n",
    "    # Read grayscale images (supports 8-bit or 16-bit)\n",
    "    test_image = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE | cv2.IMREAD_ANYDEPTH)\n",
    "    gt_image = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE | cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    # Check if images were successfully read\n",
    "    if test_image is None or gt_image is None:\n",
    "        print(f\"Warning: Unable to read images {test_path} or {gt_path}, skipping this pair\")\n",
    "        return None, None\n",
    "    \n",
    "    # Ensure image dimensions match\n",
    "    if test_image.shape != gt_image.shape:\n",
    "        print(f\"Warning: Dimensions of {test_path} and {gt_path} do not match, skipping this pair\")\n",
    "        return None, None\n",
    "    \n",
    "    # Binarize images using Otsu's method\n",
    "    _, test_binary = cv2.threshold(test_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    _, gt_binary = cv2.threshold(gt_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Convert to 1D arrays and normalize to 0-1 range\n",
    "    test_flat = (test_binary.flatten() / 255).astype(int)\n",
    "    gt_flat = (gt_binary.flatten() / 255).astype(int)\n",
    "    \n",
    "    # Calculate F1 score (handle zero-division cases)\n",
    "    f1 = f1_score(gt_flat, test_flat, zero_division=0)\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    r = np.corrcoef(test_flat, gt_flat)[0, 1]\n",
    "    \n",
    "    return f1, r\n",
    "\n",
    "# Define image pairs (each pair contains prefixes of test image and ground truth image)\n",
    "image_groups = [\n",
    "    (\"01_Tubulin\", \"1_Tubulin\"),\n",
    "    (\"02_Vimentin\", \"2_Vimentin\"),\n",
    "    (\"03_PKC\", \"3_PKC\"),\n",
    "    (\"04_Chx10\", \"4_Chx10\"),\n",
    "    (\"05_SV2\", \"5_SV2\"),\n",
    "    (\"06_Synapsin\", \"6_Synapsin\")\n",
    "]\n",
    "\n",
    "# Path to the folder containing images\n",
    "folder_path = \"D://Customized algorithm for DySpec//7_pixel_evaluation\"\n",
    "\n",
    "# Iterate through all pairs and calculate metrics\n",
    "for test_prefix, gt_prefix in image_groups:\n",
    "    # Construct image paths (assuming images are in tif format)\n",
    "    test_path = os.path.join(folder_path, f\"{test_prefix}.tif\")\n",
    "    gt_path = os.path.join(folder_path, f\"{gt_prefix}.tif\")\n",
    "    \n",
    "    print(f\"\\nProcessing: {test_prefix} and {gt_prefix}\")\n",
    "    f1, r = calculate_metrics(test_path, gt_path)\n",
    "    \n",
    "    if f1 is not None and r is not None:\n",
    "        print(f\"F1 score: {f1:.4f}\")\n",
    "        print(f\"Pearson correlation coefficient (R): {r:.4f}\")\n",
    "\n",
    "print(\"\\nAll pairs processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 F1 score and person correction efficient with manual threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 1.0000\n",
      "Pearson correlation coefficient (R): 1.0000\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Read 8-bit (or 16-bit) grayscale images\n",
    "test_image = cv2.imread('D://Customized algorithm for DySpec//7_pixel_evaluation///reconstructed image.tif', cv2.IMREAD_GRAYSCALE)\n",
    "groundtruth_image = cv2.imread('D://Customized algorithm for DySpec//7_pixel_evaluation//adjacent IF image.tif', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if images were successfully read\n",
    "if test_image is None or groundtruth_image is None:\n",
    "    print(\"Unable to read images, please check file paths and filenames.\")\n",
    "else:\n",
    "    # Use a fixed threshold of 10 for binarization (This value can be adjusted based on actual conditions)\n",
    "    _, test_binary = cv2.threshold(test_image, 1, 255, cv2.THRESH_BINARY)\n",
    "    _, groundtruth_binary = cv2.threshold(groundtruth_image, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Convert binary images to one-dimensional arrays\n",
    "    test_flat = test_binary.flatten()\n",
    "    groundtruth_flat = groundtruth_binary.flatten()\n",
    "\n",
    "    # Convert arrays to 0 and 1 format\n",
    "    test_flat = (test_flat / 255).astype(int)\n",
    "    groundtruth_flat = (groundtruth_flat / 255).astype(int)\n",
    "\n",
    "    # Calculate F1 score, setting zero_division parameter\n",
    "    f1 = f1_score(groundtruth_flat, test_flat, zero_division=0)\n",
    "\n",
    "    print(f\"F1 score: {f1:.4f}\")\n",
    "\n",
    "    # Calculate Pearson correlation coefficient\n",
    "    r = np.corrcoef(test_flat, groundtruth_flat)[0, 1]\n",
    "    print(f\"Pearson correlation coefficient (R): {r:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
